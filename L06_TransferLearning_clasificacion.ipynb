{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/twyncoder/tf-hands-on/blob/master/L06_TransferLearning_clasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><a href=\"https://centroia.uva.es/\"> <img src=\"logo-UVAIA-original.png\" alt=\"Header\" style=\"width: 300px;\"/> </a></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Redes de Aprendizaje Profundo básicas con Keras y Tensorflow.\n",
        "## *Transfer Learning*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Preparación del entorno "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_name + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_name)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "def print_history(history,title=None, extension='png'):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    #plt.gca().set_ylim(0, 1)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    if(title!=None):\n",
        "        plt.title(title)\n",
        "        save_fig(title,fig_extension=extension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Información de versiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comprobar si disponemos de una GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Inspeccionar los datos y crear subconjuntos train, test, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUmHOMqu4vi7",
        "outputId": "b3a4960f-a8d5-48af-8106-29af3e5445f7"
      },
      "outputs": [],
      "source": [
        "!mkdir cracktyres\n",
        "!unzip cracktyres.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para cargar las imágenes y etiquetas desde los archivos CSV\n",
        "def load_data(csv_file, img_dir):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    file_paths = data.iloc[:, 0].values\n",
        "    labels = data.iloc[:, 1:].values\n",
        "\n",
        "    paths = [os.path.join(img_dir, file) for file in file_paths]\n",
        "\n",
        "    return paths, labels\n",
        "\n",
        "# Función para cargar y preprocesar las imágenes\n",
        "def preprocess_image(image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0  # Normalización a [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Función para crear un dataset tf.data a partir de las rutas y etiquetas\n",
        "def create_dataset(paths, labels, batch_size):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    image_label_ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
        "\n",
        "    ds = image_label_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds = ds.shuffle(buffer_size=len(paths))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar las rutas y etiquetas de las imágenes\n",
        "train_paths, train_labels = load_data('./cracktyres/train/_classes.csv', './cracktyres/train')\n",
        "valid_paths, valid_labels = load_data('./cracktyres/valid/_classes.csv', './cracktyres/valid')\n",
        "test_paths, test_labels = load_data('./cracktyres/test/_classes.csv', './cracktyres/test')\n",
        "\n",
        "# Crear los datasets\n",
        "batch_size = 16\n",
        "train_dataset = create_dataset(train_paths, train_labels, batch_size)\n",
        "valid_dataset = create_dataset(valid_paths, valid_labels, batch_size)\n",
        "test_dataset = create_dataset(test_paths, test_labels, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar las imágenes del conjunto de entrenamiento\n",
        "def show_images(dataset, num_images):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for images, labels in dataset.take(1):  # Tomar el primer batch\n",
        "        for i in range(num_images):\n",
        "            ax = plt.subplot(4, 8, i + 1)\n",
        "            plt.imshow(images[i])\n",
        "            label = 'Problema' if labels[i][0] == 1 else 'OK'\n",
        "            plt.title(label)\n",
        "            plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imprimir las primeras 32 imágenes del dataset de entrenamiento\n",
        "show_images(train_dataset, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Entrenar red neuronal para clasificación binaria de neumáticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ahora puedes usar estos datasets para entrenar tu modelo\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')  # 2 para clasificación binaria con one-hot\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_history(history,\"L06_cnn_basic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**¡AHORA TÚ!** \n",
        "- ¿Qué tal ha ido el aprendizaje? ¿Puede estar habiendo _overfitting_? Si es así, ¿a qué crees que es debido?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar el modelo\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Utilizar Data augmentation para prevenir el _overfitting_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, label, augment=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0  # Normalización a [0, 1]\n",
        "\n",
        "    if augment:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "        image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "        image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
        "        image = tf.image.random_hue(image, max_delta=0.1)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# Función para crear un dataset tf.data a partir de las rutas y etiquetas\n",
        "def create_dataset(paths, labels, batch_size, augment=False):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    image_label_ds = tf.data.Dataset.zip((path_ds, label_ds))\n",
        "\n",
        "    ds = image_label_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds = ds.shuffle(buffer_size=len(paths))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos probar a entrenar el mismo modelo para ver el efecto de _Data Augmentation_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')  # 2 para clasificación binaria con one-hot\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history2 = model.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_history(history2,\"L06_cnn_augment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... Y también podemos entrenar nuevos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**¡AHORA TÚ! (OPCIONAL)** \n",
        "- Prueba a entrenar modelos más avanzados y utilizando distintas técnicas de regularización.\n",
        "- Piensa en utilizar valores de _learning rate_ pequeños o, mejor aún... técnicas dinámicas de ajuste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1xKO15s-CzX"
      },
      "source": [
        "# 4. Reconocimiento con redes pre-entrenadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Cuando disponemos de pocos datos para los entrenamientos, es buena idea aprovechar modelos ya pre-entrenados que puedan sernos útiles.\n",
        "- Como vimos anteriormente, Keras dispone de algunos modelos ya pre-entrenados con el dataset de _imagenet_ que son muy útiles para clasificación.\n",
        "- Ahora aprovecharemos la extracción de características aprendida por uno de estos modelos para crear nuestro clasificador de neumáticos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRs2xPGLAQfp",
        "outputId": "ea62fca6-3d46-4591-8168-3e4a37f65e10"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para adaptar la red es necesario:\n",
        "- No alterar (inicialmente) los valores entrenados de los kernels de convolución de las primeras capas.  \n",
        "- Ajustar la capa _fully connected_ o `Dense()` de salida al número de clases que necesitemos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjpbb8chASny"
      },
      "outputs": [],
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuwDDAyUAWxN"
      },
      "outputs": [],
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create model\n",
        "model7 = keras.Model(inputs,outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FC236K6Aq4X",
        "outputId": "f8a1655e-817a-48fd-ae23-fbeb3eee45f8"
      },
      "outputs": [],
      "source": [
        "model7.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a prevenir el _overfitting_ empleando un callback de _Early Stopping_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=4,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLLBY2Z2AfIi"
      },
      "outputs": [],
      "source": [
        "model7.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P99H69rmApWV",
        "outputId": "a5cf6e73-e3d2-4cb4-a58d-74cdf6a170b5"
      },
      "outputs": [],
      "source": [
        "history7 = model7.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=100,\n",
        "                    callbacks=[early_stopping_cb,model_checkpoint_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "L5Z2uIF6A7ks",
        "outputId": "1cfdd6cc-cd93-4891-d4ae-dd03a16d37f3"
      },
      "outputs": [],
      "source": [
        "print_history(history7,\"L06_PretrainedVGG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model7.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Fine tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M_gHnNaBLvm"
      },
      "source": [
        "Los resultados anteriores no están nada mal, ¿Podemos mejorarlo?\n",
        "- Vamos a reentrenar el modelo completo permitiendo ahora que se modifiquen los kernels de las capas de extracción de características.\n",
        "- Utilizaremos un valor de _learning rate_ muy pequeño para no perjudicar e entrenamiento anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du31FjRLBTR1"
      },
      "outputs": [],
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Compile the model with a low learning rate\n",
        "model7.compile(#optimizer=keras.optimizers.RMSprop(learning_rate = 1e-05),\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=1e-04, beta_1=0.9, beta_2=0.999),\n",
        "              loss = 'categorical_crossentropy' , metrics = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNPOx_9qCRxT"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,verbose=1)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model_7tuned.keras\", save_best_only=True)\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5, patience=3,verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fawEc1svCM3X",
        "outputId": "8fcbf27c-7d0b-4299-a56a-1eb2f7025120"
      },
      "outputs": [],
      "source": [
        "history73 = model7.fit(train_dataset,\n",
        "                    validation_data=valid_dataset,\n",
        "                    epochs=15,\n",
        "                    callbacks=[early_stopping_cb,model_checkpoint_cb,lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "r0hdP-80CkCE",
        "outputId": "ef82cd62-5e9d-4830-b5ed-b5243bf2e4b6"
      },
      "outputs": [],
      "source": [
        "print_history(history73,\"L07_VGG_finetuning_callbacks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZAevGyBC5As"
      },
      "outputs": [],
      "source": [
        "model7.evaluate(test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
